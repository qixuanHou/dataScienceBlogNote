### What is big data 
IBM data scientist break big data into 4 dimensions: 
* Volume (Scale of data), 
* Variety (Different forms of data), 
* Velocity (Analysis of streaming data), 
* Veracity (Uncertainty of data).

Traditional database management system is used to store and process relational and structured data only. 

### what is Hadoop
Hadoop is a framework to process Big Data. It is a framework that allows to store and process large data sets in parallel and distributed fashion.
Two major parts of Hadoop
* Hadoop Distributed File System (HDFS) 
  takes care of storage part of Hadoop architecture
* MapReduce
  processing modal and software framework for writing applications which can run on Hadoop. The programs are capable of processing big data in parallel on large clusters of computational nodes

#### what is HDFS
stores files across many nodes in a cluster
name node -> data node 
* name node - maintains and manages data node, records metadata, inforamtion about data blocks
* data node - stores actual data

 https://www.datasciencecentral.com/profiles/blogs/hadoop-for-beginners
 https://www.datasciencecentral.com/profiles/blogs/hadoop-for-beginners-part-2
